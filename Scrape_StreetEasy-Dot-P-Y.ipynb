{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying ML to Predict NYC Real Estate Value & Investment Opportunity\n",
    "\n",
    "*This notebook scrapes streeteasy.com for data on listings for sale in the Five Boroughs and applies ML to evaluate my predictive model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "# from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "# from selenium.common.exceptions import TimeoutException\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "# from retrying import retry\n",
    "import tenacity\n",
    "# import json\n",
    "# import os\n",
    "# from collections import OrderedDict\n",
    "# from urlparse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boroughs = ['manhattan','brooklyn','queens','bronx','staten-island']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def url_def(lst):\n",
    "    lst_of_urls = []\n",
    "    for item in lst:\n",
    "        lst_of_urls.append('http://streeteasy.com/for-sale/'+str(item)+'/status:listed?refined_search=true')\n",
    "    return lst_of_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://streeteasy.com/for-sale/manhattan/status:listed?refined_search=true',\n",
       " 'http://streeteasy.com/for-sale/brooklyn/status:listed?refined_search=true',\n",
       " 'http://streeteasy.com/for-sale/queens/status:listed?refined_search=true',\n",
       " 'http://streeteasy.com/for-sale/bronx/status:listed?refined_search=true',\n",
       " 'http://streeteasy.com/for-sale/staten-island/status:listed?refined_search=true']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls = url_def(boroughs)\n",
    "urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features\n",
    "\n",
    "What would be the most useful features to collect for this project?\n",
    "\n",
    "- **Type of house, Location of house, Neighborhood, Number of rooms, number of baths**, availability of amenities in building (laundry, doorman, super)?, proximity to transit, proximity to waterfront, (with the Price of house as target).\n",
    "\n",
    "Features in bold are available on streeteasy...\n",
    "\n",
    "Q. ***Can any useful features be engineered from those available or retrieved from an alternate source?***\n",
    "\n",
    "### Scraped features\n",
    "\n",
    "The features available from Streeteasy.com are:\n",
    "\n",
    " - House type, Geo-location, House address, No. of beds, No. of baths, Square area of house, Neighborhood, Price\n",
    " \n",
    "*What features can be derived from these? What additional insight will these derived features provide?*\n",
    "*Can more useful features be retrieved from other sources to complement Streeteasy?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listing_type = []\n",
    "lat = []\n",
    "lng = []\n",
    "address = []\n",
    "no_of_beds = []\n",
    "no_of_baths = []\n",
    "sq_area = []\n",
    "n_hood = []\n",
    "borough = []\n",
    "price = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Thoughts*\n",
    "\n",
    "Do the project requirements dictate the statistical method/algorithm used? Will these, in turn, determine whether categorical or continuous variables are required?\n",
    "\n",
    "- *(Multi)Linear Regression*\n",
    "- *Logistic Regression?* **(No. This is not a classification task...)**\n",
    "- *Random forest*\n",
    "\n",
    "**I'm going with numerical variables where possible...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def page_scrape(page):\n",
    "    # count = 0\n",
    "    # On slow connections...\n",
    "    # result = WebDriverWait(page, 30).until(EC.presence_of_element_located((By.ID, 'result-details')))\n",
    "    # listings = result.find_element_by_tag_name('ul').find_element_by_tag_name('li')\n",
    "    listings = page.find_element_by_id('result-details').find_element_by_tag_name('ul').find_elements_by_tag_name('li')\n",
    "    # collect data here by iterating through each listing and appending to our lists\n",
    "    for l in listings[:14]:\n",
    "        # I need an IF statement to test whether the listing is legit before scraping to reduce the amount of N/A values\n",
    "        # Initiating a counter to help identify at what listing the code breaks, if it does...\n",
    "        # This has become redundant with the introduction of tenacity retry function\n",
    "        # count +=1\n",
    "        \n",
    "        # longitude and latitude\n",
    "        g = None\n",
    "        try:\n",
    "            g = l.get_attribute('se:map:point')\n",
    "            if g:\n",
    "                lt, ln = g.split(',')\n",
    "                lat.append(float(lt))\n",
    "                lng.append(float(ln))\n",
    "            else:\n",
    "                lat.append('N/A')\n",
    "                lng.append('N/A')\n",
    "        except:\n",
    "            lat.append('N/A')\n",
    "            lng.append('N/A')\n",
    "        # time.sleep(1)\n",
    "        \n",
    "        # address\n",
    "        ad = None\n",
    "        try:\n",
    "            ad = l.find_element_by_class_name('details-title').text.split('\\n')[0]\n",
    "            if ad:\n",
    "                address.append(ad)\n",
    "            else:\n",
    "                address.append('N/A')\n",
    "        except:\n",
    "            address.append('N/A')\n",
    "        # time.sleep(1)\n",
    "        \n",
    "        # price\n",
    "        p = None\n",
    "        try:\n",
    "            p = float(l.find_element_by_class_name('price').text.replace('$','').replace(',', ''))\n",
    "            if p:\n",
    "                price.append(p)\n",
    "            else:\n",
    "                price.append('N/A')\n",
    "        except:\n",
    "            price.append('N/A')\n",
    "        # time.sleep(1)\n",
    "        \n",
    "        # number of beds\n",
    "        bd_detail = None\n",
    "        try:\n",
    "            bd_detail = l.find_element_by_class_name('details_info').find_element_by_tag_name('span')\n",
    "            if bd_detail.text.find('bed') > 0:\n",
    "                no_of_beds.append(float(bd_detail.text.split(' ')[0]))\n",
    "            # do we want this as a string or float? what are the regression/ml requirements?\n",
    "            else:\n",
    "                no_of_beds.append('N/A')\n",
    "        except:\n",
    "            no_of_beds.append('N/A')\n",
    "        # time.sleep(1)\n",
    "        \n",
    "        # number of baths\n",
    "        baths = None\n",
    "        try:\n",
    "            lstn_details = l.find_element_by_class_name('details_info').find_elements_by_tag_name('span')\n",
    "            for detail in lstn_details:\n",
    "                if detail.text.find('bath') > 0:\n",
    "                    try:\n",
    "                        baths = float(detail.text.split(' ')[0])\n",
    "                    except:\n",
    "                        baths = 'N/A'\n",
    "        except:\n",
    "            baths = 'N/A'\n",
    "        no_of_baths.append(baths)\n",
    "        # time.sleep(1)\n",
    "        \n",
    "        # square area NB: value in previous listing is being appended to next listing. FIX!\n",
    "        # update: fixed.\n",
    "        area = None\n",
    "        try:\n",
    "            l_details = l.find_element_by_class_name('details_info').find_elements_by_tag_name('span')\n",
    "            for detail in l_details:\n",
    "                 if detail.text.find('ft') > 0:\n",
    "                    area = float(detail.text.split(' ')[0].replace(',', ''))\n",
    "            if area:\n",
    "                sq_area.append(area)\n",
    "            else:\n",
    "                sq_area.append('N/A')\n",
    "        except:\n",
    "            sq_area.append('N/A')\n",
    "        # time.sleep(1)\n",
    "        \n",
    "        # listing type and neighborhood\n",
    "        l_type = None\n",
    "        nhood = None\n",
    "        try:\n",
    "            area_details = l.find_elements_by_class_name('details_info')[1].text\n",
    "            l_type, nhood = area_details.split(' in ')\n",
    "            if l_type:\n",
    "                listing_type.append(l_type)\n",
    "            else:\n",
    "                listing_type.append('N/A')\n",
    "            if nhood:\n",
    "                n_hood.append(nhood)\n",
    "            else:\n",
    "                n_hood.append('N/A')\n",
    "        except:\n",
    "            listing_type.append('N/A')\n",
    "            n_hood.append('N/A')\n",
    "        # time.sleep(1)\n",
    "    # if count == 14:\n",
    "        # print('Moving on to the next page...')\n",
    "    # streeteasy introduces a captcha when they suspect scraping. How will this be overridden?\n",
    "    # fixed by using Firefox in place of Chrome\n",
    "    \n",
    "    return listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To navigate to the next page. Self-explanatory, really...\n",
    "\n",
    "def next_page():\n",
    "    nxt = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CLASS_NAME, 'next')))\n",
    "    # formerly: nxt = listns[-1].find_element_by_class_name('next'); WebDriverWait improves stability\n",
    "    nxt.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To \"refresh\" the browser page if a 300000ms TimeoutException occurs due to page crashing...\n",
    "\n",
    "@tenacity.retry()\n",
    "def retry():\n",
    "    driver.get(driver.current_url)\n",
    "\n",
    "# OR: \n",
    "# ret = tenacity.Retrying(retry=tenacity.retry_if_exception_type(TimeoutException))\n",
    "# ret.call(driver.get(driver.currentl_url))\n",
    "\n",
    "# checkpointing using ediblepickle package is another option...    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying...\n",
      "323.078999996\n",
      "324.131999969\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "# manhattan almost done, restarting with brooklyn due to strange firefox memory crash; using range(1,)\n",
    "for x in range(0, len(urls)):\n",
    "    start_borough_time = time.time()\n",
    "    counter = 1\n",
    "    page_crash = 0\n",
    "    driver = webdriver.Firefox()\n",
    "    driver.get(urls[x])\n",
    "    time.sleep(2) # possible crash here without time.sleep?\n",
    "    listns = page_scrape(driver)\n",
    "    last_page = int(listns[-1].find_elements_by_class_name('page')[-1].text)\n",
    "    # print 'Counter:', counter\n",
    "    next_page()\n",
    "    for i in range(1, last_page):\n",
    "        try:\n",
    "            counter += 1 # increment repetition may occur here if a break occurs in this try loop... avoided by using scraping in except loop\n",
    "            # borough.append(boroughs[x])\n",
    "            listns = page_scrape(driver)\n",
    "            next_page()\n",
    "        except:\n",
    "            page_crash += 1\n",
    "            print 'Retrying...'\n",
    "            # ret.call(driver.get(driver.current_url))\n",
    "            retry()\n",
    "        finally:\n",
    "            delay = random.uniform(0.5, 1)\n",
    "            time.sleep(delay)\n",
    "    \n",
    "    print time.time() - start_borough_time\n",
    "    driver.close()\n",
    "    \n",
    "    dic = {'building type':listing_type, 'latitude':lat, 'longitude':lng, 'address':address, 'beds':no_of_beds, 'baths':no_of_baths, 'area':sq_area, 'neighborhood':n_hood, 'price':price}\n",
    "    data = pd.DataFrame(dic)\n",
    "    data.to_csv(boroughs[x]+'.csv', index=False)\n",
    "    \n",
    "    # re-initializing lists\n",
    "    listing_type = []\n",
    "    lat = []\n",
    "    lng = []\n",
    "    address = []\n",
    "    no_of_beds = []\n",
    "    no_of_baths = []\n",
    "    sq_area = []\n",
    "    n_hood = []\n",
    "    borough = []\n",
    "    price = []\n",
    "print time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(dic)\n",
    "data.to_csv('Queens.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>area</th>\n",
       "      <th>baths</th>\n",
       "      <th>beds</th>\n",
       "      <th>building type</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>834 Sterling Place #PH4</td>\n",
       "      <td>N/A</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Condo</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Crown Heights</td>\n",
       "      <td>890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>288 Albany Avenue</td>\n",
       "      <td>3000</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>Multi-family</td>\n",
       "      <td>40.6705</td>\n",
       "      <td>-73.9396</td>\n",
       "      <td>Crown Heights</td>\n",
       "      <td>1.299e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1291 Gates</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>Multi-family</td>\n",
       "      <td>40.6943</td>\n",
       "      <td>-73.9177</td>\n",
       "      <td>Bushwick</td>\n",
       "      <td>1.275e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>798 Knickerbocker Avenue</td>\n",
       "      <td>N/A</td>\n",
       "      <td>None</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>40.6925</td>\n",
       "      <td>-73.9078</td>\n",
       "      <td>N/A</td>\n",
       "      <td>2.395e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>160 Imlay Street #3A5</td>\n",
       "      <td>1245</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Condo</td>\n",
       "      <td>40.6805</td>\n",
       "      <td>-74.0103</td>\n",
       "      <td>Red Hook</td>\n",
       "      <td>1.325e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    address  area baths beds building type latitude longitude  \\\n",
       "0   834 Sterling Place #PH4   N/A     1    2         Condo        0         0   \n",
       "1         288 Albany Avenue  3000     2    5  Multi-family  40.6705  -73.9396   \n",
       "2                1291 Gates   N/A     4    6  Multi-family  40.6943  -73.9177   \n",
       "3  798 Knickerbocker Avenue   N/A  None  N/A           N/A  40.6925  -73.9078   \n",
       "4     160 Imlay Street #3A5  1245     2    1         Condo  40.6805  -74.0103   \n",
       "\n",
       "    neighborhood      price  \n",
       "0  Crown Heights     890000  \n",
       "1  Crown Heights  1.299e+06  \n",
       "2       Bushwick  1.275e+06  \n",
       "3            N/A  2.395e+06  \n",
       "4       Red Hook  1.325e+06  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic = {'building type':listing_type, 'latitude':lat, 'longitude':lng, 'address':address, 'beds':no_of_beds, 'baths':no_of_baths, 'area':sq_area, 'neighborhood':n_hood, 'price':price}\n",
    "data = pd.DataFrame(dic)\n",
    "data.to_csv('Brooklyn.csv')\n",
    "# The data is not yet good enough to warrant saving to disk...\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>area</th>\n",
       "      <th>baths</th>\n",
       "      <th>beds</th>\n",
       "      <th>building type</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6545</th>\n",
       "      <td>66-68 Washington Avenue #5R</td>\n",
       "      <td>1123</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Condo</td>\n",
       "      <td>40.6967</td>\n",
       "      <td>-73.9678</td>\n",
       "      <td>Clinton Hill</td>\n",
       "      <td>699000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6546</th>\n",
       "      <td>405 Dean Street #4A</td>\n",
       "      <td>1125</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Condo</td>\n",
       "      <td>40.6828</td>\n",
       "      <td>-73.9778</td>\n",
       "      <td>Park Slope</td>\n",
       "      <td>689000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6547</th>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6548</th>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6549</th>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          address  area baths beds building type latitude  \\\n",
       "6545  66-68 Washington Avenue #5R  1123     1    2         Condo  40.6967   \n",
       "6546          405 Dean Street #4A  1125     1    1         Condo  40.6828   \n",
       "6547                          N/A   N/A   N/A  N/A           N/A      N/A   \n",
       "6548                          N/A   N/A   N/A  N/A           N/A      N/A   \n",
       "6549                          N/A   N/A   N/A  N/A           N/A      N/A   \n",
       "\n",
       "     longitude  neighborhood   price  \n",
       "6545  -73.9678  Clinton Hill  699000  \n",
       "6546  -73.9778    Park Slope  689000  \n",
       "6547       N/A           N/A     N/A  \n",
       "6548       N/A           N/A     N/A  \n",
       "6549       N/A           N/A     N/A  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12376 entries, 0 to 12375\n",
      "Data columns (total 9 columns):\n",
      "address          12376 non-null object\n",
      "area             12376 non-null object\n",
      "baths            12297 non-null object\n",
      "beds             12376 non-null object\n",
      "building type    12376 non-null object\n",
      "latitude         12376 non-null object\n",
      "longitude        12376 non-null object\n",
      "neighborhood     12376 non-null object\n",
      "price            12376 non-null object\n",
      "dtypes: object(9)\n",
      "memory usage: 870.3+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       address   area    baths     beds building type      latitude  \\\n",
      "count    12376  12376  12297.0  12376.0         12376  12376.000000   \n",
      "unique   10444   2389     28.0     21.0             9   2066.000000   \n",
      "top        N/A    N/A      1.0      2.0         Condo     40.772022   \n",
      "freq        20   3717   4509.0   3803.0          6738    177.000000   \n",
      "\n",
      "           longitude     neighborhood      price  \n",
      "count   12376.000000            12376    12376.0  \n",
      "unique   1724.000000              100     1971.0  \n",
      "top       -73.990588  Upper West Side  2995000.0  \n",
      "freq      177.000000              930      114.0  \n"
     ]
    }
   ],
   "source": [
    "print data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling 'N/A' values, duplicates and outliers...\n",
    "\n",
    "*Are samples with missing data discarded or replaced with the feature median? What is the norm as pertains to this situation...?*\n",
    "\n",
    "I would rather discard than replace with the median for now to avoid introducing any form of bias.\n",
    "\n",
    "*Are statistical outliers really outliers in this use case? (Yes/**No**)?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean-up, Pre-processing and Exploratory Data Analysis\n",
    "[Click here](Preprocessing_EDA_FeatureSelection.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
